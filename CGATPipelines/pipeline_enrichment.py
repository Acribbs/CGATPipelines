##############################################################################
#
#   MRC FGU CGAT
#
#   $Id$
#
#   Copyright (C) 2009 Andreas Heger
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################
"""===========================
Pipeline template
===========================

:Author: Andreas Heger
:Release: $Id$
:Date: |today|
:Tags: Python

.. Replace the documentation below with your own description of the
   pipeline's purpose

Overview
========

This pipeline computes the word frequencies in the configuration
files :file:``pipeline.ini` and :file:`conf.py`.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_enrichment.py config

Input files
-----------

None required except the pipeline configuration files.

Requirements
------------

The pipeline requires the results from
:doc:`pipeline_annotations`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

On top of the default CGAT setup, the pipeline requires the following
software to be in the path:

.. Add any additional external requirements such as 3rd party software
   or R modules below:

Requirements:

* samtools >= 1.1

Pipeline output
===============

.. Describe output files of the pipeline here

Glossary
========

.. glossary::


Code
====

"""
from ruffus import *
from ruffus.combinatorics import *
import sys
import os
import sqlite3
import CGAT.Experiment as E
import CGATPipelines.Pipeline as P
import CGAT.IOTools as IOTools
import shutil
import PipelineGSEnrichment as PipelineEnrichment

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])

# -----------------------------------------------
# Utility functions
def connect():
    '''utility function to connect to database.

    Use this method to connect to the pipeline database.
    Additional databases can be attached here as well.

    Returns an sqlite3 database handle.
    '''

    dbh = sqlite3.connect(PARAMS["database"])
    statement = '''ATTACH DATABASE '%s' as annotations''' % (
        PARAMS["annotations_database"])
    cc = dbh.cursor()
    cc.execute(statement)
    cc.close()

    return dbh

# ---------------------------------------------------
# Specific pipeline tasks

FOREGROUNDS = ["*_foreground.tsv"]
USERBACKGROUNDS = PARAMS['background_compareallto'].split(",")
CONFIG = ["*_config.tsv", "*_mapping.tsv"]


@follows(mkdir("backgrounds.dir"))
@follows(mkdir("ontologies.dir"))
@transform(CONFIG, regex("(.*)_(.*).tsv"),
           [r"backgrounds.dir/\1_genestoterms.tsv",
            r"backgrounds.dir/\1_termstogenes.tsv",
            r"ontologies.dir/\1_ont.tsv"])
def parseAnnotations(infile, outfiles):
    '''
    Reads a set of annotations and generates an AnnotationSet object and
    a parsed output.
    A default background set is generated with all the annotated genes.
    '''
    g2t, t2g, ont = outfiles
    onts = dict()
    descs = dict()
    for PARAM in PARAMS:
        if PARAM.split("_")[0] == "ontologies":
            onts[PARAM] = PARAMS[PARAM]
        elif PARAM.split("_")[0] == "termdescs":
            descs[PARAM] = PARAMS[PARAM]
    if infile.split("_")[-1].replace(".tsv", "") == "config":
        AS = PipelineEnrichment.AnnotationSet(infile,
                                              True, onts, descs)
    else:
        AS = PipelineEnrichment.AnnotationSet(infile,
                                              False, onts, descs)
    AS.build()
    AS.stow(g2t, t2g, ont)


@transform(parseAnnotations, suffix(".tsv"), ".load")
def loadAnnotations(infiles, outfile):
    '''
    Loads each annotation set into the database.
    '''
    for inf in infiles:
        tabnam = inf.replace(".tsv", ".load")
        if os.path.getsize(inf) > 0:
            P.load(inf, tabnam)
        else:
            os.system("touch %s" % tabnam)


@active_if(int(PARAMS["hpa_run"]) == 1)
@transform(parseAnnotations,
           regex("backgrounds.dir/(.*)_genestoterms.tsv"),
           [r"backgrounds.dir/\1_hpa_genestoterms.tsv",
            r"backgrounds.dir/\1_hpa_termstogenes.tsv"])
def buildHPABackground(infiles, outfiles):
    '''
    Builds a background geneset based on human protein atlas expression values
    specified in pipeline.ini.
    '''
    geneset = PipelineEnrichment.HPABackground(PARAMS['hpa_tissue'],
                                               PARAMS['hpa_minlevel'],
                                               PARAMS['hpa_supportive'])
    hpageneset = PipelineEnrichment.translateGeneSet(
        geneset,
        PARAMS['hpa_translatetab'],
        PARAMS['hpa_fromcol'],
        PARAMS['hpa_tocol'])

    AS = PipelineEnrichment.AnnotationSet()
    AS.rebuild(infiles[0], infiles[1], infiles[2])
    AS.subSetAnnotations(hpageneset)
    AS.stow(outfiles[0], outfiles[1], noOnt=True)


@active_if(len(USERBACKGROUNDS) != 0)
@product(parseAnnotations,
         formatter(".+/(?P<NAM>.*)_genestoterms.tsv"),
         USERBACKGROUNDS,
         formatter(".+/(?P<NAM>.*).tsv"),
         [r"backgrounds.dir/{NAM[0][0]}""_user""{NAM[1][0]}_genestoterms.tsv",
          r"backgrounds.dir/{NAM[0][0]}""_user""{NAM[1][0]}_termstogenes.tsv"])
def defineUserBackgrounds(infiles, outfiles):
    '''
    Reads user defined gene lists and generates backgrounds for each
    annotation set.
    '''
    usergenes = PipelineEnrichment.inputSet(infiles[1])
    AS = PipelineEnrichment.AnnotationSet()
    AS.rebuild(infiles[0][0], infiles[0][1], infiles[0][2])
    AS.subSetAnnotations(usergenes)
    AS.stow(outfiles[0], outfiles[1], noOnt=True)


@follows(mkdir("annotated_foregrounds.dir"))
@product(parseAnnotations,
         formatter(".+/(?P<NAM>.*)_.*.tsv"),
         FOREGROUNDS,
         formatter(".+/(?P<NAM>.*).tsv"),
         [r"annotated_foregrounds.dir/{NAM[0][0]}""_""{NAM[1][0]}_genestoterms.tsv",
          r"annotated_foregrounds.dir/{NAM[0][0]}""_""{NAM[1][0]}_termstogenes.tsv"])
def annotateFG(infiles, outfiles):
    '''
    Annotates the foreground gene lists using an Annotation set
    '''
    genelist = PipelineEnrichment.inputSet(infiles[1])
    AS = PipelineEnrichment.AnnotationSet()
    AS.rebuild(infiles[0][0], infiles[0][1], infiles[0][2])
    AS.subSetAnnotations(genelist)
    AS.stow(outfiles[0], outfiles[1], noOnt=True)


@follows(mkdir("fisher_test.dir"))
@follows(defineUserBackgrounds)
@follows(buildHPABackground)
@transform(annotateFG,
           regex("annotated_foregrounds.dir/(.*).genestoterms.tsv"),
           add_inputs("backgrounds.dir/*"),
           r"fisher_test.dir/\1.tsv")
def runFisher(infiles, outfile):
    FG = PipelineEnrichment.AnnotationSet()
    FG.rebuild(infiles[0][0], infiles[0][1])
    stem = infiles[0][0].split("/")[-1].split("_")[0]
    files = []
    for bg in infiles[1:]:
        T = P.getTempFilename(".")
        bgnam = bg.replace("backgrounds.dir/", "")
        if bgnam.startswith(stem) and bg.split("_")[-1] == "genestoterms.tsv":
            t2g = bg.replace("genestoterms", "termstogenes")

            Fisher = PipelineEnrichment.StatsTest(
                [infiles[0][0], infiles[0][1]], [bg, t2g])
            Fisher.TermForTerm()
            Fisher.writeScores(T, bgnam)
        files.append(T)
    out = IOTools.openFile(outfile, "w")
    for f in files:
        with IOTools.openFile(f) as infile:
            for line in infile:
                out.write(line)
        os.remove(f)
    out.close()


@transform(runFisher, suffix(".tsv"), "_significant.tsv")
def getSignificant(infile, outfile):
    sigthreshold = float(PARAMS['statistics_pthresh'])
    out = IOTools.openFile(outfile, "w")
    with IOTools.openFile(infile) as inf:
        for line in inf:
            p = float(line.strip().split("\t")[-1])
            if p <= sigthreshold:
                out.write(line)
    out.close()


@follows(mkdir("report"))
def build_report():
    '''build report from scratch.

    Any existing report will be overwritten.
    '''

    E.info("starting report build process from scratch")
    P.run_report(clean=True)


@follows(mkdir("report"))
def update_report():
    '''update report.

    This will update a report with any changes inside the report
    document or code. Note that updates to the data will not cause
    relevant sections to be updated. Use the cgatreport-clean utility
    first.
    '''

    E.info("updating report")
    P.run_report(clean=False)


@follows(update_report)
def publish_report():
    '''publish report in the CGAT downloads directory.'''

    E.info("publishing report")
    P.publish_report()

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
